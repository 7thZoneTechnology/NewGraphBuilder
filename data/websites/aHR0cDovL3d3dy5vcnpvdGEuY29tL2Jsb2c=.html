<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" prefix="og: http://ogp.me/ns#">
 <head profile="http://gmpg.org/xfn/11"> 
  <title>Blog |</title> 
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> 
  <!--link rel="shortcut icon" href="http://www.orzota.com/favicon.ico" /--> 
  <link rel="shortcut icon" href="http://www.orzota.com/wp-content/themes/orzota/favicon.ico"> 
  <link rel="stylesheet" media="all" href="http://www.orzota.com/wp-content/themes/orzota/all.css" type="text/css"> 
  <link href="http://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" type="text/css"> 
  <link rel="stylesheet" type="text/css" media="all" href="http://www.orzota.com/wp-content/themes/orzota/style.css"> 
  <!-- This site is optimized with the Yoast WordPress SEO plugin v1.5.2 - http://yoast.com/wordpress/seo/ --> 
  <meta name="description" content="The Orzota blog provides useful information for developers and architects on a wide variety of big data topics"> 
  <link rel="canonical" href="http://www.orzota.com/blog-page/"> 
  <link rel="next" href="http://www.orzota.com/blog-page/page/2/"> 
  <meta property="og:locale" content="en_US"> 
  <meta property="og:type" content="website"> 
  <meta property="og:title" content="Blog -"> 
  <meta property="og:url" content="http://www.orzota.com/blog-page/"> 
  <!-- / Yoast WordPress SEO plugin. --> 
  <link rel="stylesheet" href="http://www.orzota.com/wp-content/plugins/xhanch-my-twitter/css/css.php" type="text/css" media="screen">
  <style type="text/css">/*<![CDATA[*/ #xmt_Primary_wid.xmt ul li.tweet_list{min-height:57px}  /*]]>*/</style>
  <link rel="stylesheet" id="digg-digg-css" href="http://www.orzota.com/wp-content/plugins/digg-digg/css/diggdigg-style.css?ver=5.3.6" type="text/css" media="screen"> 
  <script type="text/javascript" src="http://www.orzota.com/wp-includes/js/jquery/jquery.js?ver=1.8.3"></script> 
  <script type="text/javascript" src="http://www.orzota.com/wp-content/plugins/xhanch-my-twitter/js/marquee.js?ver=3.5.1"></script> 
  <script type="text/javascript" src="http://www.orzota.com/wp-content/plugins/xhanch-my-twitter/js/innerfade.js?ver=3.5.1"></script> 
  <link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://www.orzota.com/xmlrpc.php?rsd"> 
  <link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://www.orzota.com/wp-includes/wlwmanifest.xml"> 
  <script type="text/javascript">var ajaxurl = "http://www.orzota.com/wp-admin/admin-ajax.php"</script> 
  <!-- Dynamic Widgets by QURL - http://www.qurl.nl //--> 
  <script type="text/javascript" src="http://www.orzota.com/wp-content/themes/orzota/js/jquery.main.js"></script> 
  <script type="text/javascript">
			var _gaq = _gaq || [];
		 	_gaq.push(['_setAccount', 'UA-33751189-2']);
		 	_gaq.push(['_trackPageview']);
			(function() {
    				var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    				ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    				var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  			})();
		</script> 
 </head> 
 <body> 
  <div id="wrapper"> 
   <div class="header_bg"> 
    <div id="header"> 
     <strong class="logo"><a href="http://www.orzota.com"></a></strong> 
     <ul id="nav" class="navigation-main">
      <li id="menu-item-12" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-12"><a href="http://www.orzota.com/">Home</a></li> 
      <li id="menu-item-1126" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1126"><a href="http://www.orzota.com/bigdata/">Product</a></li> 
      <li id="menu-item-1453" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1453"><a href="http://www.orzota.com/retail-ecommerce/">Solution</a></li> 
      <li id="menu-item-25" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-25"><a href="http://www.orzota.com/services/">Services</a></li> 
      <li id="menu-item-1229" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1229"><a href="http://www.orzota.com/case-studies/">Case Studies</a></li> 
      <li id="menu-item-253" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-253"><a href="http://www.orzota.com/company/">About Us</a> 
       <div class="drop">
        <ul class="sub-menu"> 
         <li id="menu-item-714" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-714"><a href="http://www.orzota.com/company/">Company</a></li> 
         <li id="menu-item-693" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-693"><a href="http://www.orzota.com/customers/">Customers</a></li> 
         <li id="menu-item-738" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-738"><a href="http://www.orzota.com/partners/">Partners</a></li> 
         <li id="menu-item-165" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-165"><a href="http://www.orzota.com/idc/">India Center</a></li> 
         <li id="menu-item-11" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-11"><a href="http://www.orzota.com/contact/">Contact</a></li> 
        </ul>
       </div> </li> 
      <li id="menu-item-614" class="menu-item menu-item-type-post_type menu-item-object-page active page_item page-item-609 current_page_item current_page_parent menu-item-614"><a href="http://www.orzota.com/blog-page/">Blog</a></li> 
     </ul> 
    </div> 
   </div> 
   <div id="main"> 
    <div class="main-holder"> 
     <div id="content"> 
      <div class="post" id="post-1408"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/5-steps-to-running-etl/" rel="bookmark" title="Permanent Link to 5 Steps to Running ETL for Web Companies">5 Steps to Running ETL for Web Companies</a></h2> 
        <p class="info"><strong class="date">October 1st, 2014</strong> by Shanti Subramanyam</p> 
       </div> 
       <div class="content"> 
        <p><em>NOTE: This article first appeared on <a href="http://www.datanami.com/2014/09/01/five-steps-to-running-etl-on-hadoop-for-web-companies/" target="_blank">Datanami</a></em></p> 
        <p>Mention ETL (Extract, Transform and Load) and eyes glaze over. The thought goes: “That stuff is old and meant for clunky enterprise data warehouses. What does it have to do with my internet/web/ecommerce application?”</p> 
        <p>Quite a lot – actually. ETL did originate in enterprise IT where data from online databases is <b>E</b><i>xtracted</i>, then <b>T</b><i>ransformed</i> to normalize it and finally <b>L</b><i>oaded</i> into enterprise data warehouses for analysis. Although internet companies feel they have no use for expensive, proprietary data warehouses, the fact of the matter is that ETL is still a requirement and so is some kind of a data warehouse. The logic is simple: one doesn’t run business reports on the database powering the online application.</p> 
        <h2>An ETL Example</h2> 
        <p>Consider the classic example of key transformation. The application database uses a customer_id to index into the customer table, while the CRM system has the same customer referenced differently. The business analyst wants to analyze how customers are using the product and thus, the data warehouse needs a distinct way to refer to customers i.e. the keys need to be transformed and mapped to a new key in the DW. Even if there is a single source system, it is still a good idea to do such transformations to isolate the warehouse from the online database. In addition to such basic transformations, data is also often enriched (as for example using geocodes) to create the target customer record in the warehouse. There is no getting away from it: ETL is a requirement whether you are the hottest social media company or a 50-year-old bank.</p> 
        <h2>Why Hadoop?</h2> 
        <p>All right. We need ETL. But what has Hadoop got do with it?</p> 
        <p>Turns out that Hadoop is an ideal platform to run ETL. You can feed the results into a traditional data warehouse, or better yet, simply use Hadoop itself as your warehouse. Two for the price of one! And ingesting data from all sources into a centralized Hadoop repository is future proof: as your business scales and the data grows rapidly, the Hadoop infrastructure can scale easily.</p> 
        <p>The Hadoop platform has tools that can extract the data from the source systems, whether they are log files, machine data or online databases and load them to Hadoop in record time. It is possible to do transformations on the fly as well, although more elaborate processing is better done after the data is loaded into Hadoop. Programming and scripting frameworks allow complex ETL jobs to be deployed and executed in a distributed manner. Rapid improvements in interactive SQL tools make Hadoop an ideal choice for a low cost data warehouse.</p> 
        <p>Got it. What needs to be done to get this all to work? Read on to find out.</p> 
        <h2>ETL Process in Hadoop</h2> 
        <p>An architecture for setting up a Hadoop data store for ETL is shown below.</p> 
        <p><img class="aligncenter" alt="ETL Architecture" src="http://2s7gjr373w3x22jf92z99mgm5w.wpengine.netdna-cdn.com/wp-content/uploads/2014/08/5-steps-for-ETL-Hadoop.png" width="509" height="368"></p> 
        <p>Here are the typical steps to setup Hadoop for ETL:</p> 
        <ol> 
         <li>Setup a Hadoop cluster</li> 
         <li>Connect data sources</li> 
         <li>Define the metadata</li> 
         <li>Create the ETL jobs</li> 
         <li>Create the workflow</li> 
        </ol> 
        <h3>Setup a Hadoop Cluster</h3> 
        <p>This step can be really simple or quite difficult depending on where you want the cluster to be. On the public cloud, you can create a Hadoop cluster with just a few clicks using Amazon EMR, Rackspace CBD or other cloud Hadoop offerings. If the data sources are already on the same public cloud, then this is obviously the no-brainer solution.</p> 
        <p>If however your data sources happen to be in a Data Center, there are several things to take into consideration.</p> 
        <ol> 
         <li>Can the data be moved to the cloud? Legal, security, privacy and cost considerations apply.</li> 
         <li>Can test data be used for development?</li> 
        </ol> 
        <p>If the answer is No to both questions, then a cluster will need to be provisioned in the Data Center. Go befriend your IT/OPS guy right away.</p> 
        <h3>Connect Data Sources</h3> 
        <p>The Hadoop eco-system includes several technologies such as <a href="http://flume.apache.org">Apache Flume</a> and <a href="http://sqoop.apache.org">Apache Sqoop</a> to connect various data sources such as log files, machine data and RDBMS. Depending on the amount of data and the rate of new data generation, a data ingestion architecture and topology must be planned. Start small and iterate just like any other development project. The goal is to move the data into Hadoop at a frequency that meets analytics requirements.</p> 
        <h3>Define the Metadata</h3> 
        <p>Hadoop is a “schema-on-read” platform and there is no need to create a schema before loading data as databases typically require. That does not mean one can throw in any kind of data and expect some magic to happen. It is still important to clearly define the semantics and structure of data (the “metadata”) that will be used for analytics purposes. This definition will then help in the next step of data transformation.</p> 
        <p>Going back to our example of the customer id, define how exactly this id will be stored in the warehouse. Is it a 10 digit numeric key that will be generated by some algorithm or is it simply appending a 4 digit sequence number to an existing id?</p> 
        <p>Many Hadoop projects are begun without any clear definition of Metadata. Just like ETL, the term “<a href="http://en.wikipedia.org/wiki/Meta-data_management">Metadata Management</a>” is considered old school and meant for traditional Enterprise IT, not for our modern data architecture? But in reality, metadata is crucial for the success of Hadoop as a data warehouse. With a clear design and documentation, there is no ambiguity in what a particular field means or how it was generated. Investing up front in getting this right will save a lot of angst later on.</p> 
        <p>With the metadata defined, this can be easily transposed to Hadoop using <a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog+UsingHCat">Apache HCatalog</a>, a technology provides a relational table view of data in Hadoop. HCatalog also allows this view to be shared by different type of ETL jobs, Pig, Hive or MapReduce.</p> 
        <h3>Create the ETL jobs</h3> 
        <p>We can finally focus on the process of transforming the various sources of data. Here again, multiple technologies exist: MapReduce, Cascading and Pig are some of the most common used frameworks for developing ETL jobs. Which technology to use and how to create the jobs really depends on the data set and what transformations are needed. Many organizations use a combination of Pig and MapReduce while others use Cascading exclusively. Learn about all the different ways transform jobs are done and the strengths and weaknesses of the various technologies.</p> 
        <p>A word of caution – engineers experienced in enterprise data management may be prone to aggressive data cleansing and transformation. They want order and the data to confirm to pre-defined schemas. However, the whole notion of big data is that it can be unstructured. Machine and sensor data are likely to be noisy, social media and other data may not fit into neat buckets. <a href="http://www.orzota.com/making_big_data_better/">Too much cleansing</a> can get rid of the very insights that big data promises. A thoughtful approach is required to get the most value from your data.</p> 
        <h3>Create the Workflow</h3> 
        <p>Data cleansing and transformations are easier done when multiple jobs cascade into a workflow, each performing a specific task. Often data mappings/transformations need to be executed in a specific order and/or there may be dependencies to check. These dependencies and sequences are captured in workflows – parallel flows allow parallel execution that can speed up the ETL process. Finally the entire workflow needs to be scheduled. They may have to run weekly, nightly or perhaps even hourly.</p> 
        <p>Although technologies such as <a href="http://oozie.apache.org">Oozie</a> provide some workflow management, it is typically insufficient. Many organizations create their own workflow management tools. This can be a complex process as it is important to take care of failure scenarios and restart the workflow appropriately.</p> 
        <p>A smooth workflow will result in the source data being ingested and transformed based on the metadata definition and stored in Hadoop. At this point, the data is ready for analysis. And you guessed it! There are many different ways to do that with Hadoop; <a href="http://hive.apache.org">Hive</a>, <a href="http://impala.io/">Impala</a> and <a href="http://www.cascading.org/projects/lingual/">Lingual</a> provide SQL-on-Hadoop functionality while several commercial BI tools can connect to Hadoop to explore the data visually and generate reports.</p> 
        <h3>Celebrate!</h3> 
        <p>We are finally done! We have created a data warehouse in Hadoop. Although this seems complicated (depending on the data and requirements), almost all of the technologies are open-source and available for free. Tools are now <a href="http://www.orzota.com/bigdata">emerging</a> that help automate some part of this process. If your organization does not have the expertise, it may be a good idea to engage outside services to get started on this new architecture and technologies, while hiring/training your own staff.</p> 
        <p>Data warehouses are a requirement even for web/internet companies. Data cleansing, data transformation, ETL, metadata are all terms that are still relevant for new data architectures. But they don’t need to be created using proprietary, expensive products. Leveraging Big Data technologies such as Hadoop will ensure your data architecture stands the test of time (at least until the next big wave!)</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts in hadoop" rel="category tag">hadoop</a>, <a href="http://www.orzota.com/category/uncategorized/" title="View all posts in Uncategorized" rel="category tag">Uncategorized</a></li> 
         <li><a href="http://www.orzota.com/5-steps-to-running-etl/#respond" title="Comment on 5 Steps to Running ETL for Web Companies">No Comments</a></li> 
         <!--
					<li>Tags: <a href="http://www.orzota.com/tag/etl/" rel="tag">ETL</a>, <a href="http://www.orzota.com/tag/hadoop/" rel="tag">Hadoop</a></li>					--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1389"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/backup-to-hadoop/" rel="bookmark" title="Permanent Link to Move your Database Backup to Hadoop">Move your Database Backup to Hadoop</a></h2> 
        <p class="info"><strong class="date">August 17th, 2014</strong> by Shanti Subramanyam</p> 
       </div> 
       <div class="content"> 
        <p><em>A version of this article first appeared in the<a title="Online Backup News" href="http://onlinebackupnews.com/2014/08/top-reasons-use-hadoop-database-data-warehouse-backup/" target="_blank"> Online Backup News </a>Journal.</em></p> 
        <p>For the past few years, we have heard a lot about the benefits of Hadoop, the dominant big data technology. But one less spoken of use case is backing databases to Hadoop.</p> 
        <p><a href="http://www.orzota.com/wp-content/uploads/2014/08/Slide41.png"><img class="aligncenter size-medium wp-image-1391" alt="Slide4" src="http://www.orzota.com/wp-content/uploads/2014/08/Slide41-300x82.png" width="444" height="143"></a></p> 
        <h2>Data Warehouse Backup to Hadoop</h2> 
        <p>Data Warehouses, especially large ones are expensive and doing backups by replication to another DW is out of the question for many enterprises. Consequently, the method of choice to backup a data warehouse is quite often tape. Tape backup is neither cheap nor fast. Further, a restore from a backup can cause significant disruption to business depending on the time taken. Yet, there has been no other cost-effective solution until now.</p> 
        <p>By using commodity hardware and cheap disks that are replicated, Hadoop has proven to be a safe and fast backup solution. The backup solution is easy to setup and the attractive costs and recovery time make it an ideal choice for this important function. One of our customers, a major bank, took this approach and saved a <a href="http://www.orzota.com/wp-content/uploads/2014/04/casestudy-augmentDW.pdf" target="_blank">considerable amount of money</a> while avoiding a large Data Warehouse upgrade.</p> 
        <p>The other big advantage is that the backup system is live and the data in it can be analyzed. Use Hive, Impala or Lingual and users will never know whether they are accessing the active data warehouse or a backup!</p> 
        <p>Traditional backups are always squirreled away into hiding, never to be seen by engineers or analysts. In contrast, the Hadoop solution is not just active, fast and cheap but can be used for analytics.</p> 
        <h2>Online Database Backup to Hadoop</h2> 
        <p>It is not just large data warehouses that can benefit from backing to Hadoop, but online, relational databases as well.</p> 
        <p>As online databases get larger, many DBAs prefer online backups with the ability to do point in time recovery. This allows for fast restores – a very important requirement for online databases. To ensure reliable, fast backup and restores, expensive SAN/NAS or specialized disk drives are used. Every backup makes a physical copy of the database and depending on the frequency of backups and the number of backups you want to retain, the storage costs quickly add up.</p> 
        <p>In contrast, consider a Hadoop backup solution. Hadoop uses commodity servers with vanilla disks, achieving its scale and reliability because of its redundant, distributed architecture. You can even cobble together a Hadoop cluster using older equipment, perhaps beefing up the disks depending on the amount of storage required.</p> 
        <p>Backup your database as usual; then copy it over to the Hadoop cluster. Multiple backups can all be safely stored in the same cluster.</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts in hadoop" rel="category tag">hadoop</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
					<li>Tags: <a href="http://www.orzota.com/tag/backup/" rel="tag">backup</a>, <a href="http://www.orzota.com/tag/data-warehouse/" rel="tag">data warehouse</a>, <a href="http://www.orzota.com/tag/database/" rel="tag">database</a>, <a href="http://www.orzota.com/tag/hadoop/" rel="tag">Hadoop</a></li>					--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1367"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/hadoop-as-the-source-of-truth/" rel="bookmark" title="Permanent Link to Hadoop as the source of truth">Hadoop as the source of truth</a></h2> 
        <p class="info"><strong class="date">July 29th, 2014</strong> by Shanti Subramanyam</p> 
       </div> 
       <div class="content"> 
        <p><em>This article was originally published on <a title="Hadoop as the source of truth" href="http://sandhill.com/article/hadoop-as-the-source-of-truth/">SandHill.com</a>.</em></p> 
        <link href="https://plus.google.com/+ShantiSubramanyam?rel=author" rel="publisher"> For the past few years, we have heard a lot about the benefits of augmenting the Enterprise Data Warehouse with Hadoop. The Data Warehouse vendors as well as the Hadoop vendors have been very careful with their terminology and showcasing how Hadoop can handle unstructured data while the EDW will continue to remain as the central source of truth in an enterprise.
        <br> That message was a desperate attempt by Teradata to hold on to its worldview while partnering with Hadoop vendors to ensure they stay on message as well.
        <br> Well, the game is over. With the rapid evolution of robust enterprise features like security, data management, governance, and enhanced SQL capabilities, Hadoop is all set to be the single source of truth in the enterprise.
        <p></p> 
        <h1>Data Warehouse Augmentation with Hadoop</h1> 
        <p>One of the first use cases for Hadoop in the enterprise was off-loading ETL tasks from the Enterprise Data Warehouse (EDW). Since Hadoop is excellent at batch processing, running ETL on Hadoop was an obvious choice. This provided the big benefit of saving precious resources on the EDW, leaving it to handle the more interactive and complex analytical queries. However, the term “<b><i>off-load</i></b>” or “<b><i>migrate</i></b>” ETL to Hadoop had negative connotations for Data Warehouse vendors who were concerned that this meant that Hadoop could do things that were traditionally done in the EDW at a much lower cost. Thus was born the term “<b><i>augmentation</i></b>”. Hadoop was not off-loading the EDW; it was augmenting it. The typical DW augmentation architecture thus shows Hadoop running ETL jobs and sending the results to the EDW.</p> 
        <p><a href="http://www.orzota.com/wp-content/uploads/2014/07/hadoop-dw-augment.png"><img class="aligncenter size-large wp-image-1368" alt="DW augmentation with Hadoop" src="http://www.orzota.com/wp-content/uploads/2014/07/hadoop-dw-augment-1024x735.png" width="741" height="531"></a></p> 
        <p>The advantage of this architecture is that the EDW is still the center of the data universe in an enterprise. Downstream data marts and BI tools and applications continue to work in the exact same manner, thus requiring no new tools or training for the business analysts. For first-time Hadoop users, this architecture makes sense – start small with a new technology, don’t chew more than you can bite.</p> 
        <h2>Other DW Use Cases</h2> 
        <p>Of course, once Hadoop entered the enterprise, there was no stopping it. Within Data Warehousing itself, it is now used in myriads of applications, including:</p> 
        <ul> 
         <li><b>Off-loading Computations</b>: Run ETL on Hadoop</li> 
         <li><b>Off-loading Storage</b>: Move cold data (not often used) from EDW to Hadoop</li> 
         <li><b>Backup and Recovery</b>: Replace tape backup with an active Hadoop cluster</li> 
         <li><b>Disaster Recovery</b>: Use Hadoop in the DR site to backup the EDW</li> 
        </ul> 
        <p>Notice that none of the above touches unstructured data – we are only talking about traditional Enterprise Data Warehousing and how Hadoop can make a difference in both reducing cost and increasing performance, while providing improved access to the data resources. Some of our customers have realized <a href="http://www.orzota.com/wp-content/uploads/2014/04/casestudy-augmentDW.pdf">significant cost savings</a> using Hadoop to augment the EDW.</p> 
        <h1>Hadoop for Analytics</h1> 
        <p>The big promise of Hadoop is the potential to gain new business insights with advanced predictive analytics enabled by the processing of new sources of unstructured data (social media, multimedia, etc.) in combination with data from the EDW. However, using it for online, real-time analytics has been a problem until now. Hadoop’s architecture and MapReduce framework makes it slow for real-time processing; its design point was batch.</p> 
        <p>This is the reason for the continued center stage of the Enterprise Data Warehouse. Databases like Teradata are excellent at performing complex, analytical queries on large amounts of data at great speeds.</p> 
        <h2>SQL on Hadoop</h2> 
        <p>Although the Hadoop community recognized the need for SQL early on, it is only in the last year or two that great strides have been made to create an enterprise-grade SQL solution that can meet the needs of data warehousing analytics.</p> 
        <p>The Hortonworks Stinger initiative has <a href="http://hortonworks.com/labs/stinger/">dramatically improved performance</a> for interactive queries in Hive, the dominant SQL-on-Hadoop technology.</p> 
        <p>Cloudera developed Impala from scratch, touting <a href="http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html">MPP database like performance</a>.</p> 
        <p>Meanwhile, Apache Spark has gained momentum, replacing MapReduce to focus on real-time, streaming analytics. Spark SQL holds much promise, and along with the likes of Hive and Impala, developers and users will have multiple technologies to choose from.</p> 
        <p>As adoption increases and the products mature, Hadoop will be more powerful than the MPP databases of today. We will see a shift from “<i>augmentation</i>” to “<i>replacement</i>” of the EDW with Hadoop.</p> 
        <h1>The New Enterprise Data Architecture</h1> 
        <p>With all the pieces for real-time, streaming analytics and enterprise features such as security (all Hadoop vendors now have security built-in), data management and governance with the likes of Apache Falcon, Hadoop is ready to become the source of truth in the enterprise. No longer does it need to play second fiddle to the data warehouse, it IS the data warehouse. In fact, in many Internet and technology companies, the data warehouse is built solely on Hadoop. Let us examine what this architecture might look like.</p> 
        <p style="text-align: center;"><a href="http://www.orzota.com/wp-content/uploads/2014/07/hadoop-truth-arch.jpg"><img class="aligncenter size-full wp-image-1369" title="Hadoop as the source of truth" alt="Hadoop as the source of truth" src="http://www.orzota.com/wp-content/uploads/2014/07/hadoop-truth-arch.jpg" width="720" height="540"></a></p> 
        <p>In the new enterprise architecture, Hadoop as the source of truth takes center stage. Businesses comfortable with their existing BI and reporting products can continue to use them as the products adapt to access the Big Data platform. Enterprise developers can build custom tools and applications while data scientists use big data exploratory and predictive analytics tools to obtain new business insights. This is after all the true promise of Big Data; combine multiple sources of information and create predictive and prescriptive analytical models.</p> 
        <p>This transition from Hadoop augmenting the Data Warehouse to replacing it as the source of truth in larger enterprises can be undertaken in a phased approach with new analytical applications being served from Hadoop while the EDW still feeds the legacy BI applications.</p> 
        <p>Data warehousing vendors recognize this – they are coming up with creative ways to stay relevant. Both Teradata and more recently Oracle have technologies that allow queries to span across Hadoop and the database, allowing Hadoop to process data stored in it while the database continues to handle the structured data. This is another good intermediate step in the transition process (albeit making one more dependent on the EDW, not less!)</p> 
        <h1>Conclusion</h1> 
        <p>It is a matter of time before the Enterprise Data Warehouse as we know it, with expensive proprietary appliances and software technologies becomes obsolete. The open source Hadoop eco-system is thriving and evolving very rapidly to perform all of the storage, compute and analytics required while providing dramatic new functionality to handle huge amounts of unstructured and semi-structured data. All of this functionality comes at a fraction of the cost. This ecosystem has proven that it is no longer true that innovation happens only in closed source, proprietary companies.</p> 
        <p>Hadoop as the source of truth in the enterprise is almost here. If your enterprise is yet to begin the Hadoop journey, step on the pedal – otherwise you may be left behind.</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/big-data-strategy/" title="View all posts in Big Data Strategy" rel="category tag">Big Data Strategy</a>, <a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts in hadoop" rel="category tag">hadoop</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
					<li>Tags: <a href="http://www.orzota.com/tag/data-warehouse-augmentation/" rel="tag">data warehouse augmentation</a>, <a href="http://www.orzota.com/tag/edw/" rel="tag">EDW</a>, <a href="http://www.orzota.com/tag/enterprise-data-warehouse/" rel="tag">enterprise data warehouse</a>, <a href="http://www.orzota.com/tag/hadoop/" rel="tag">Hadoop</a>, <a href="http://www.orzota.com/tag/teradata/" rel="tag">Teradata</a></li>					--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1259"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/big-data-projects-to-fail/" rel="bookmark" title="Permanent Link to What causes some Big Data projects to fail?">What causes some Big Data projects to fail?</a></h2> 
        <p class="info"><strong class="date">May 1st, 2014</strong> by Bharath Mundlapudi</p> 
       </div> 
       <div class="content"> 
        <p>These days, we often see many articles talking about Big Data in various verticals – manufacturing, media, insurance, oil &amp; gas, finance &amp; retail etc. We are living in interesting times and the next 5 years will be fantastic w.r.t quality and safety of life on many fronts – travel safety, innovation in life science, new product discoveries in manufacturing, targeting customers with right products which they care about, assessing the degree of risk to the corporation at any given point with very high accuracy and so on. All these benefits are made possible primary due to ‘Big Data Technologies’ – Hadoop, Cassandra, MongoDB, to name a few.</p> 
        <p>At Orzota, we have helped customers ranging from SMBs to large corporations in many verticals – retail, financial and manufacturing. We have provided solutions on public clouds like AWS and Rackspace, private clouds using OpenStack, and of course in data centers ranging from a few nodes to thousands of nodes.</p> 
        <p>With this experience and knowledge, I’d like to share some of the scenarios that can go wrong, if one is not careful,&nbsp; causing big data projects to fail. Hopefully, these highlighted areas will provoke some thought and help you plan and execute big data projects correctly and of course under planned budget!</p> 
        <p>Here are a few areas that can cause big data projects to fail:</p> 
        <p>1. Traditional way of thinking</p> 
        <p>2. Not having clear strategy and roadmap</p> 
        <p>3. Treating Hadoop as yet another data platform</p> 
        <p>4. Not clearly defining the use case(s) to solve</p> 
        <p>5. Technology focus rather than business focus</p> 
        <p>6. Selecting the wrong tool for the job</p> 
        <p>7. Not knowing and planning data access patterns</p> 
        <p>8. Not having the right team</p> 
        <p>And of course, there are many other areas where one could go wrong in Big Data projects. We will continue to share our experience. Do <a href="http://www.orzota.com/contact">contact us</a> for any help at any stage of your Big Data project life cycle.</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/big-data-strategy/" title="View all posts in Big Data Strategy" rel="category tag">Big Data Strategy</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1238"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/big-data-enterprise-data-warehouse/" rel="bookmark" title="Permanent Link to Big Data in the Enterprise Data Warehouse">Big Data in the Enterprise Data Warehouse</a></h2> 
        <p class="info"><strong class="date">April 28th, 2014</strong> by Shanti Subramanyam</p> 
       </div> 
       <div class="content"> 
        <p>The role of the Enterprise Data Warehouse (EDW) is to integrate data across operational systems which may be in operational silos and geographically distributed. The diagram below shows a typical architecture of a data warehouse.</p> 
        <h2>Enterprise Data Warehouse Architecture</h2> 
        <p><a href="http://www.orzota.com/wp-content/uploads/2014/04/Slide1.jpg"><img class="aligncenter size-full wp-image-1245" alt="Slide1" src="http://www.orzota.com/wp-content/uploads/2014/04/Slide1.jpg" width="720" height="540"></a></p> 
        <link href="https://plus.google.com/+ShantiSubramanyam?rel=author" rel="publisher"> The ETL software extracts data, transforms values to normalize data, filters and cleanses “bad” data and finally loads data into a target database. &nbsp;Data from operational systems such as various transactional databases, ERP and CRM systems are loaded into the Enterprise Data Warehouse (EDW). Some businesses require a Staging area to synchronize data coming from different timezones, geographies or to handle other disparities. 
        <p style="text-align: left;">The EDW in most large businesses is not accessed directly but through data marts. Data marts are typically departmentalized. The HR department is interested in information about employees, the sales department about sales and so on. Some data marts are refreshed daily, while others weekly or monthly.</p> 
        <h3 style="text-align: left;">Data Warehouse as Source of Truth</h3> 
        <p>The EDW was considered the single version of truth across all disparate internal and external systems. Data is stored at a fine-grained level recording for example, every sale so the data can be sliced and diced in different ways. However, not all enterprise data is stored in a data warehouse, only data that is necessary for business insight and decisions. Still, EDWs tend to be large, storing 100s of GBs of structured data, either in a relational database or columnar store (columnar refers to the method of storage, the databases themselves are still relational; examples include Teradata and Greenplum).</p> 
        <h2>Big Data in the Enterprise Data Warehouse</h2> 
        <p>What can Big Data do for the Enterprise Data Warehouse? Quite a lot, actually.</p> 
        <p>According to a recent survey by TDWI, some of the reasons for the expansion of the Data Warehousing Environment to include Big Data technologies such as Hadoop are:</p> 
        <ul> 
         <li>advanced analytics</li> 
         <li>increasing volume of data</li> 
         <li>requirement for real-time processing</li> 
         <li>raw data exploration</li> 
        </ul> 
        <p>But there are much simpler ways to start on Big Data.&nbsp; Hadoop provides the ability to archive and backup the EDW, off-load routine processing and infrequently used data. This can dramatically improve the performance and lowers the cost of the Enterprise Data Warehouse; all this without implementing a single new application!</p> 
        <h2>&nbsp;Data Warehouse Augmentation</h2> 
        <p>The architecture below shows a first step to take on the big data journey with data warehouse augmentation.</p> 
        <p><a href="http://www.orzota.com/wp-content/uploads/2014/04/Slide2.jpg"><img class="aligncenter size-full wp-image-1246" alt="Slide2" src="http://www.orzota.com/wp-content/uploads/2014/04/Slide2.jpg" width="720" height="540"></a></p> 
        <p>This architecture provides several benefits:</p> 
        <ul> 
         <li>Store a large amount of data in Hadoop which becomes the single source of truth</li> 
         <li>Move the infrequently used data from the EDW to Hadoop, thus lowering costs (sometimes dramatically)</li> 
         <li>Run ETL, reports and other types of analytics directly on Hadoop</li> 
         <li>Store only the critical data needed for fast analytics and BI in the data warehouse</li> 
         <li>Allow data scientists to conduct exploratory analytics of the raw data in Hadoop directly</li> 
         <li>No disruption to existing business analysts and reporting functions</li> 
        </ul> 
        <h2>Conclusion</h2> 
        <p>Big Data is disrupting the Enterprise Data Warehouse in a big way. When faced with a variety of daunting goals and applications, it can be difficult to figure out how to get started on Big Data. At <a title="Big Data Services" href="http://www.orzota.com/services/">Orzota</a>, we believe that the best strategy is to start small, exploit Big Data meaningfully before moving on to bigger things.</p> 
        <p>Orzota has experience creating roadmaps, strategy and big data architecture for augmenting enterprise data warehouses with big data technologies such as hadoop. <a href="http://orzota.com/contact">Contact us</a> to schedule a free one hour consultation.</p> 
        <p>&nbsp;</p> 
        <p>&nbsp;</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/big-data-strategy/" title="View all posts in Big Data Strategy" rel="category tag">Big Data Strategy</a>, <a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts in hadoop" rel="category tag">hadoop</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
					<li>Tags: <a href="http://www.orzota.com/tag/big-data/" rel="tag">big data</a>, <a href="http://www.orzota.com/tag/big-data-warehouse/" rel="tag">big data warehouse</a>, <a href="http://www.orzota.com/tag/data-warehouse-augmentation/" rel="tag">data warehouse augmentation</a>, <a href="http://www.orzota.com/tag/enterprise-data-warehouse/" rel="tag">enterprise data warehouse</a></li>					--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1205"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/advanced-introduction-flume/" rel="bookmark" title="Permanent Link to An Advanced Introduction to Flume">An Advanced Introduction to Flume</a></h2> 
        <p class="info"><strong class="date">April 10th, 2014</strong> by Sai Sivam</p> 
       </div> 
       <div class="content"> 
        <p>Flume 3</p> 
        <p><a title="http://bit.ly/1hEaV7y" href="http://bit.ly/1hEaV7y">http://bit.ly/1hEaV7y</a></p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts in Tutorials" rel="category tag">Tutorials</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1203"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/serious-introduction-flume/" rel="bookmark" title="Permanent Link to A Serious Introduction to Flume">A Serious Introduction to Flume</a></h2> 
        <p class="info"><strong class="date">April 10th, 2014</strong> by Sai Sivam</p> 
       </div> 
       <div class="content"> 
        <p>Flume 2<br> <a title=" http://bit.ly/1iyKKjF" href=" http://bit.ly/1iyKKjF">http://bit.ly/1iyKKjF</a></p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts in Tutorials" rel="category tag">Tutorials</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1201"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/gentle-introduction-flume/" rel="bookmark" title="Permanent Link to A Gentle Introduction to Flume">A Gentle Introduction to Flume</a></h2> 
        <p class="info"><strong class="date">April 10th, 2014</strong> by Sai Sivam</p> 
       </div> 
       <div class="content"> 
        <p>Flume 1</p> 
        <p><a title="http://bit.ly/1ge2VOC" href="http://bit.ly/1ge2VOC">http://bit.ly/1ge2VOC</a></p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts in Tutorials" rel="category tag">Tutorials</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1148"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/gentle-introduction-olap/" rel="bookmark" title="Permanent Link to A Gentle Introduction to OLAP">A Gentle Introduction to OLAP</a></h2> 
        <p class="info"><strong class="date">March 7th, 2014</strong> by Sai Sivam</p> 
       </div> 
       <div class="content"> 
        <p><a title="http://bit.ly/1gggqcs" href="http://bit.ly/1gggqcs" target="_blank">http://bit.ly/1gggqcs</a></p> 
        <p>Click above link. Select Play All. Grab some food. Have a long lunch watching this.</p> 
        <p>An Online Brown Bag! <img src="http://www.orzota.com/wp-includes/images/smilies/icon_smile.gif" alt=":-)" class="wp-smiley"> </p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts in Tutorials" rel="category tag">Tutorials</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="post" id="post-1135"> 
       <div class="title"> 
        <h2><a href="http://www.orzota.com/gentle-introduction-hadoop-map-reduce/" rel="bookmark" title="Permanent Link to A Gentle Introduction to Hadoop and Map Reduce">A Gentle Introduction to Hadoop and Map Reduce</a></h2> 
        <p class="info"><strong class="date">March 2nd, 2014</strong> by Sai Sivam</p> 
       </div> 
       <div class="content"> 
        <p>My 1 hour presentation/compilation on introducing Hadoop and Map Reduce to faculty, researchers at the Pondicherry Engineering College on Jan 10 as part of a workshop there. This is a series of Youtube Video compilations for easy consumption. I use this to introduce Hadoop and Map Reduce to new engineers. I have compiled bits and pieces of videos from over the net and packaged them into a video program of less than 1 hour.</p> 
        <p><a title="http://bit.ly/1hTPdyE" href="http://bit.ly/1hTPdyE" target="_blank">http://bit.ly/1hTPdyE</a></p> 
        <p>Click above link. Select Play All. Relax and watch a smarter TV for 1 hour.</p> 
       </div> 
       <div class="meta"> 
        <ul> 
         <li>Posted in <a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts in hadoop" rel="category tag">hadoop</a>, <a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts in Tutorials" rel="category tag">Tutorials</a></li> 
         <li><span>Comments Off</span></li> 
         <!--
										--> 
        </ul> 
       </div> 
       <br>
       <br>
       <br> 
      </div> 
      <div class="navigation"> 
       <div class="next">
        <a href="http://www.orzota.com/blog-page/page/2/">Older Entries »</a>
       </div> 
       <div class="prev"></div> 
      </div> 
     </div> 
     <div class="sidebar">
      <div class="widget-1 widget-first widget-odd widget widget_rssiconwidget" id="rssiconwidget-2">
       <a href="http://feeds.feedburner.com/OrzotaBlog" target="_blank" style="color: #ff8300; padding: 12px 0px 12px 29px; background: url('http://www.orzota.com/wp-content/plugins/rss-icon-widget/icons/feed-icon-24x24.png') no-repeat 0 50%;">Subscribe via RSS</a>
      </div>
      <div class="widget-2 widget-even widget widget_search" id="search-3">
       <form role="search" method="get" id="searchform" action="http://www.orzota.com/"> 
        <div>
         <label class="screen-reader-text" for="s">Search for:</label> 
         <input type="text" value="" name="s" id="s"> 
         <input type="submit" id="searchsubmit" value="Search"> 
        </div> 
       </form>
      </div> 
      <div class="widget-3 widget-odd widget widget_recent_entries_custom" id="recent-posts-custom-3"> 
       <h3>Recent Posts</h3> 
       <ul class="blogs-list"> 
        <!--li--> 
        <div class="text-holder"> 
         <!--?php the_excerpt(); ?--> 
         <a href="http://www.orzota.com/5-steps-to-running-etl/"> 5 Steps to Running ETL for Web Companies</a> 
        </div> 
        <br> 
        <!--/li--> 
        <!--li--> 
        <div class="text-holder"> 
         <!--?php the_excerpt(); ?--> 
         <a href="http://www.orzota.com/backup-to-hadoop/"> Move your Database Backup to Hadoop</a> 
        </div> 
        <br> 
        <!--/li--> 
        <!--li--> 
        <div class="text-holder"> 
         <!--?php the_excerpt(); ?--> 
         <a href="http://www.orzota.com/hadoop-as-the-source-of-truth/"> Hadoop as the source of truth</a> 
        </div> 
        <br> 
        <!--/li--> 
        <!--li--> 
        <div class="text-holder"> 
         <!--?php the_excerpt(); ?--> 
         <a href="http://www.orzota.com/big-data-projects-to-fail/"> What causes some Big Data projects to fail?</a> 
        </div> 
        <br> 
        <!--/li--> 
        <!--li--> 
        <div class="text-holder"> 
         <!--?php the_excerpt(); ?--> 
         <a href="http://www.orzota.com/big-data-enterprise-data-warehouse/"> Big Data in the Enterprise Data Warehouse</a> 
        </div> 
        <br> 
        <!--/li--> 
       </ul> 
       <div class="box-more"> 
        <a href="http://www.orzota.com/blog-page/" class="more">More Articles</a> 
        <br>
        <br> 
       </div> 
      </div>
      <div class="widget-4 widget-even widget widget_categories" id="custom_categories-2">
       <h3>Categories</h3> 
       <ul> 
        <li class="cat-item cat-item-36"><a href="http://www.orzota.com/category/blog/big-data-strategy/" title="View all posts filed under Big Data Strategy">Big Data Strategy</a> </li> 
        <li class="cat-item cat-item-41"><a href="http://www.orzota.com/category/blog/" title="All blog posts should fall under this category">blog</a> </li> 
        <li class="cat-item cat-item-44"><a href="http://www.orzota.com/category/blog/cassandra/" title="View all posts filed under cassandra">cassandra</a> </li> 
        <li class="cat-item cat-item-28"><a href="http://www.orzota.com/category/blog/datascience/" title="View all posts filed under Data Science">Data Science</a> </li> 
        <li class="cat-item cat-item-24"><a href="http://www.orzota.com/category/blog/hadoop-2/" title="View all posts filed under hadoop">hadoop</a> </li> 
        <li class="cat-item cat-item-45"><a href="http://www.orzota.com/category/blog/hbase/" title="View all posts filed under hbase">hbase</a> </li> 
        <li class="cat-item cat-item-50"><a href="http://www.orzota.com/category/blog/search/" title="View all posts filed under Search">Search</a> </li> 
        <li class="cat-item cat-item-16"><a href="http://www.orzota.com/category/blog/tutorials/" title="View all posts filed under Tutorials">Tutorials</a> </li> 
        <li class="cat-item cat-item-1"><a href="http://www.orzota.com/category/uncategorized/" title="View all posts filed under Uncategorized">Uncategorized</a> </li> 
       </ul> 
      </div>
      <div class="widget-5 widget-last widget-odd widget widget_tag_cloud" id="tag_cloud-2">
       <h3>Tags</h3>
       <div class="tagcloud">
        <a href="http://www.orzota.com/tag/apache/" class="tag-link-48" title="1 topic" style="font-size: 8pt;">apache</a> 
        <a href="http://www.orzota.com/tag/bdm/" class="tag-link-33" title="1 topic" style="font-size: 8pt;">BDM</a> 
        <a href="http://www.orzota.com/tag/big-data/" class="tag-link-27" title="7 topics" style="font-size: 17.545454545455pt;">big data</a> 
        <a href="http://www.orzota.com/tag/big-data-analytics/" class="tag-link-34" title="3 topics" style="font-size: 12.772727272727pt;">big data analytics</a> 
        <a href="http://www.orzota.com/tag/big-data-management/" class="tag-link-35" title="5 topics" style="font-size: 15.636363636364pt;">big data management</a> 
        <a href="http://www.orzota.com/tag/big-data-search/" class="tag-link-52" title="1 topic" style="font-size: 8pt;">big data search</a> 
        <a href="http://www.orzota.com/tag/big-data-warehouse/" class="tag-link-59" title="1 topic" style="font-size: 8pt;">big data warehouse</a> 
        <a href="http://www.orzota.com/tag/cascading/" class="tag-link-62" title="1 topic" style="font-size: 8pt;">cascading</a> 
        <a href="http://www.orzota.com/tag/cassandra/" class="tag-link-44" title="1 topic" style="font-size: 8pt;">cassandra</a> 
        <a href="http://www.orzota.com/tag/cloud-big-data/" class="tag-link-55" title="2 topics" style="font-size: 10.863636363636pt;">cloud big data</a> 
        <a href="http://www.orzota.com/tag/database/" class="tag-link-29" title="2 topics" style="font-size: 10.863636363636pt;">database</a> 
        <a href="http://www.orzota.com/tag/data-warehouse-augmentation/" class="tag-link-58" title="2 topics" style="font-size: 10.863636363636pt;">data warehouse augmentation</a> 
        <a href="http://www.orzota.com/tag/dbms/" class="tag-link-30" title="1 topic" style="font-size: 8pt;">dbms</a> 
        <a href="http://www.orzota.com/tag/eclipse/" class="tag-link-17" title="2 topics" style="font-size: 10.863636363636pt;">eclipse</a> 
        <a href="http://www.orzota.com/tag/edw/" class="tag-link-63" title="1 topic" style="font-size: 8pt;">EDW</a> 
        <a href="http://www.orzota.com/tag/enterprise-data-warehouse/" class="tag-link-60" title="2 topics" style="font-size: 10.863636363636pt;">enterprise data warehouse</a> 
        <a href="http://www.orzota.com/tag/enterprise-information-management/" class="tag-link-37" title="1 topic" style="font-size: 8pt;">enterprise information management</a> 
        <a href="http://www.orzota.com/tag/etl/" class="tag-link-56" title="2 topics" style="font-size: 10.863636363636pt;">ETL</a> 
        <a href="http://www.orzota.com/tag/hadoop/" class="tag-link-11" title="14 topics" style="font-size: 22pt;">Hadoop</a> 
        <a href="http://www.orzota.com/tag/hbase/" class="tag-link-45" title="2 topics" style="font-size: 10.863636363636pt;">hbase</a> 
        <a href="http://www.orzota.com/tag/hdfs/" class="tag-link-12" title="3 topics" style="font-size: 12.772727272727pt;">HDFS</a> 
        <a href="http://www.orzota.com/tag/hive/" class="tag-link-19" title="4 topics" style="font-size: 14.363636363636pt;">hive</a> 
        <a href="http://www.orzota.com/tag/howto/" class="tag-link-20" title="1 topic" style="font-size: 8pt;">howto</a> 
        <a href="http://www.orzota.com/tag/integration/" class="tag-link-43" title="1 topic" style="font-size: 8pt;">integration</a> 
        <a href="http://www.orzota.com/tag/jobs/" class="tag-link-23" title="1 topic" style="font-size: 8pt;">jobs</a> 
        <a href="http://www.orzota.com/tag/machine-learning/" class="tag-link-47" title="1 topic" style="font-size: 8pt;">machine learning</a> 
        <a href="http://www.orzota.com/tag/mahout/" class="tag-link-46" title="1 topic" style="font-size: 8pt;">mahout</a> 
        <a href="http://www.orzota.com/tag/mapreduce/" class="tag-link-13" title="6 topics" style="font-size: 16.75pt;">MapReduce</a> 
        <a href="http://www.orzota.com/tag/master-data-management/" class="tag-link-38" title="2 topics" style="font-size: 10.863636363636pt;">master data management</a> 
        <a href="http://www.orzota.com/tag/mdm/" class="tag-link-39" title="1 topic" style="font-size: 8pt;">MDM</a> 
        <a href="http://www.orzota.com/tag/namenode/" class="tag-link-25" title="1 topic" style="font-size: 8pt;">namenode</a> 
        <a href="http://www.orzota.com/tag/newsql/" class="tag-link-31" title="1 topic" style="font-size: 8pt;">NewSQL</a> 
        <a href="http://www.orzota.com/tag/nosql/" class="tag-link-32" title="3 topics" style="font-size: 12.772727272727pt;">NoSQL</a> 
        <a href="http://www.orzota.com/tag/pig/" class="tag-link-22" title="1 topic" style="font-size: 8pt;">Pig</a> 
        <a href="http://www.orzota.com/tag/programming/" class="tag-link-18" title="2 topics" style="font-size: 10.863636363636pt;">Programming</a> 
        <a href="http://www.orzota.com/tag/rackspace/" class="tag-link-54" title="2 topics" style="font-size: 10.863636363636pt;">rackspace</a> 
        <a href="http://www.orzota.com/tag/roi/" class="tag-link-49" title="1 topic" style="font-size: 8pt;">ROI</a> 
        <a href="http://www.orzota.com/tag/scalability/" class="tag-link-26" title="1 topic" style="font-size: 8pt;">scalability</a> 
        <a href="http://www.orzota.com/tag/search-2/" class="tag-link-51" title="1 topic" style="font-size: 8pt;">search</a> 
        <a href="http://www.orzota.com/tag/semantic-web/" class="tag-link-42" title="1 topic" style="font-size: 8pt;">semantic web</a> 
        <a href="http://www.orzota.com/tag/setup/" class="tag-link-14" title="3 topics" style="font-size: 12.772727272727pt;">setup</a> 
        <a href="http://www.orzota.com/tag/single-node-setup/" class="tag-link-15" title="1 topic" style="font-size: 8pt;">single-node setup</a> 
        <a href="http://www.orzota.com/tag/solr/" class="tag-link-53" title="1 topic" style="font-size: 8pt;">solr</a> 
        <a href="http://www.orzota.com/tag/teradata/" class="tag-link-57" title="2 topics" style="font-size: 10.863636363636pt;">Teradata</a> 
        <a href="http://www.orzota.com/tag/tutorial/" class="tag-link-21" title="2 topics" style="font-size: 10.863636363636pt;">tutorial</a>
       </div> 
      </div>
     </div>
    </div> 
   </div> 
   <div id="footer"> 
    <div class="footer-holder"> 
     <div class="bar"> 
      <ul id="nav-footer" class="nav">
       <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-12"><a href="http://www.orzota.com/">Home</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1126"><a href="http://www.orzota.com/bigdata/">Product</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1453"><a href="http://www.orzota.com/retail-ecommerce/">Solution</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-25"><a href="http://www.orzota.com/services/">Services</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1229"><a href="http://www.orzota.com/case-studies/">Case Studies</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-253"><a href="http://www.orzota.com/company/">About Us</a></li> 
       <li class="menu-item menu-item-type-post_type menu-item-object-page active page_item page-item-609 current_page_item current_page_parent menu-item-614"><a href="http://www.orzota.com/blog-page/">Blog</a></li> 
      </ul> 
     </div> 
     <div class="panel"> 
      <a href="http://www.orzota.com" class="logo-2"><img src="http://www.orzota.com/wp-content/themes/orzota/images/logo-02.png" width="236" height="52" alt="image description"></a> 
      <p>© 2013 Orzota. All Rights Reserved. </p> 
     </div> 
    </div> 
   </div> 
  </div>  
 </body>
</html>